{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Environment"
      ],
      "metadata": {
        "id": "imwTi10JQmtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "grid_size = 20\n",
        "discount_factor = 0.9\n",
        "epsilon = 0.1\n",
        "alpha = 0.1\n",
        "theta = 0.0001\n",
        "num_episodes = 10"
      ],
      "metadata": {
        "id": "HOJiBzuKQo1l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grid with obstacles\n",
        "grid = np.zeros((grid_size, grid_size))  # Empty grid\n",
        "obstacles = np.random.choice([0, 1], size=(grid_size, grid_size), p=[0.8, 0.2])  # 20% obstacles\n",
        "grid += obstacles\n",
        "print(grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvrJ1DgdQrrN",
        "outputId": "446115a3-9540-48ea-9b48-0d6743cf3564"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start and Goal Positions\n",
        "start = (np.random.randint(0, grid_size), np.random.randint(0, grid_size))\n",
        "goal = (np.random.randint(0, grid_size), np.random.randint(0, grid_size))"
      ],
      "metadata": {
        "id": "rN_jq9WpQuT8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the reward grid\n",
        "reward_grid = np.zeros_like(grid)\n",
        "reward_grid[goal] = 100  # Goal reward\n",
        "reward_grid[grid == 1] = -10  # Obstacle penalty"
      ],
      "metadata": {
        "id": "Hu1rmSGaRBKh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_grid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9wAHE9_RIWK",
        "outputId": "f4be18ec-6a93-4714-e338-0aa84f51ce26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-10.,   0.,   0., -10.,   0.,   0.,   0., -10.,   0.,   0., -10.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [-10.,   0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,   0., -10.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.],\n",
              "       [  0., -10., -10.,   0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [-10.,   0.,   0.,   0.,   0.,   0.,   0., -10.,   0.,   0., -10.,\n",
              "          0., -10.,   0.,   0.,   0., -10.,   0.,   0.,   0.],\n",
              "       [-10., -10.,   0.,   0.,   0., -10.,   0., -10.,   0., -10.,   0.,\n",
              "          0., -10.,   0., -10., -10.,   0.,   0., -10.,   0.],\n",
              "       [  0.,   0.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,   0.],\n",
              "       [  0.,   0.,   0., -10.,   0.,   0.,   0.,   0., -10.,   0.,   0.,\n",
              "          0.,   0.,   0., 100., -10.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0., -10.,   0., -10., -10.,   0.,\n",
              "          0.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0., -10.,   0.,   0.,   0., -10., -10.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0., -10.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0., -10.,   0.,   0.,   0.,   0.,   0., -10.,   0., -10.,\n",
              "          0., -10., -10.,   0.,   0.,   0.,   0.,   0., -10.],\n",
              "       [-10.,   0.,   0.,   0.,   0., -10.,   0., -10.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., -10.,   0., -10.,   0.,   0.,   0.],\n",
              "       [  0., -10.,   0.,   0.,   0.,   0.,   0.,   0., -10., -10.,   0.,\n",
              "        -10.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [-10.,   0.,   0.,   0., -10., -10.,   0., -10., -10.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0., -10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0., -10.,   0.,   0.,   0.,   0., -10.,   0.],\n",
              "       [-10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., -10.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [-10.,   0., -10.,   0., -10.,   0.,   0.,   0.,   0.,   0., -10.,\n",
              "          0.,   0.,   0.,   0.,   0., -10., -10.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0., -10., -10.,   0.,   0.,   0., -10., -10.,\n",
              "          0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,   0.],\n",
              "       [-10.,   0.,   0., -10.,   0.,   0.,   0.,   0.,   0., -10.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., -10., -10.,   0., -10.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Action space: up, down, left, right, stay\n",
        "actions = [(0, 1), (0, -1), (1, 0), (-1, 0), (0, 0)]  # (x, y) movements"
      ],
      "metadata": {
        "id": "rAepWHLBRO7k"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MDP Based Approach"
      ],
      "metadata": {
        "id": "X1qBcZO2RXvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function\n",
        "def get_next_state(state, action):\n",
        "    x, y = state\n",
        "    dx, dy = action\n",
        "    next_state = (min(max(x + dx, 0), grid_size - 1), min(max(y + dy, 0), grid_size - 1))  # Boundaries\n",
        "    if grid[next_state] == 1:  # Hit an obstacle\n",
        "        return state\n",
        "    return next_state"
      ],
      "metadata": {
        "id": "ekE174oBRWDU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Iteration Algorithm\n",
        "def value_iteration():\n",
        "    V = np.zeros((grid_size, grid_size))\n",
        "    iterations = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for x in range(grid_size):\n",
        "            for y in range(grid_size):\n",
        "                state = (x, y)\n",
        "                if state == goal:\n",
        "                    continue\n",
        "                v = V[state]\n",
        "                action_values = []\n",
        "                for i, action in enumerate(actions):\n",
        "                    next_state = get_next_state(state, action)\n",
        "                    reward = reward_grid[next_state]\n",
        "                    action_values.append(reward + discount_factor * V[next_state])\n",
        "                V[state] = max(action_values)\n",
        "                delta = max(delta, abs(v - V[state]))\n",
        "        iterations += 1\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    return V, iterations, total_time"
      ],
      "metadata": {
        "id": "7FMd0yLBRd48"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_mdp, iterations_mdp, time_mdp = value_iteration()\n",
        "print(f\"MDP: Converged in {iterations_mdp} iterations, Time taken: {time_mdp:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuxcjKWYSc8w",
        "outputId": "4e36acf2-8870-417d-fc9b-53c124880516"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MDP: Converged in 21 iterations, Time taken: 0.15 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Armed Bandit (Epsilon-Greedy) Approach"
      ],
      "metadata": {
        "id": "bqTamBqOSl-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Table for Multi-Armed Bandit approach\n",
        "Q = np.zeros((grid_size, grid_size, len(actions)))\n",
        "\n",
        "# Epsilon-greedy action selection\n",
        "def epsilon_greedy_action(state):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(len(actions))  # Explore random action\n",
        "    else:\n",
        "        return np.argmax(Q[state[0], state[1], :])  # Exploit best action"
      ],
      "metadata": {
        "id": "uf16Nc0JShY8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_bandit():\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Limit the number of steps per episode to prevent infinite loops\n",
        "    max_steps_per_episode = 100\n",
        "    for episode in range(num_episodes):\n",
        "        state = start\n",
        "        step = 0\n",
        "        while state != goal and step < max_steps_per_episode:\n",
        "            action = epsilon_greedy_action(state)\n",
        "            next_state = get_next_state(state, actions[action])\n",
        "            reward = reward_grid[next_state]\n",
        "            best_next_action = np.argmax(Q[next_state[0], next_state[1], :])\n",
        "\n",
        "            # Q-Learning update\n",
        "            Q[state[0], state[1], action] += alpha * (reward + discount_factor * Q[next_state[0], next_state[1], best_next_action] - Q[state[0], state[1], action])\n",
        "            state = next_state\n",
        "            step += 1\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "OWaKIQMRSqVg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_bandit = run_bandit()\n",
        "print(f\"Bandit: Time taken: {time_bandit:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liIzjAVQSswJ",
        "outputId": "04966cf1-39b7-4457-e024-b473182eb643"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bandit: Time taken: 90.28 seconds\n"
          ]
        }
      ]
    }
  ]
}